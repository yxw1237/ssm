[INFO] [2017-06-27 10:35:59][org.apache.kafka.clients.consumer.ConsumerConfig]ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = admin
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [192.168.1.25:32780]
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.keystore.type = JKS
	ssl.trustmanager.algorithm = PKIX
	enable.auto.commit = true
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.truststore.password = null
	session.timeout.ms = 30000
	metrics.num.samples = 2
	client.id = 
	ssl.endpoint.identification.algorithm = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	check.crcs = true
	request.timeout.ms = 40000
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 1000
	receive.buffer.bytes = 32768
	ssl.cipher.suites = null
	ssl.truststore.type = JKS
	security.protocol = PLAINTEXT
	ssl.truststore.location = null
	ssl.keystore.password = null
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	auto.offset.reset = earliest

[INFO] [2017-06-27 10:36:00][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.9.0.1
[INFO] [2017-06-27 10:36:00][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 23c69d62a0cabf06
[INFO] [2017-06-27 11:00:29][org.apache.kafka.clients.consumer.ConsumerConfig]ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = admin
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [192.168.1.25:32780]
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.keystore.type = JKS
	ssl.trustmanager.algorithm = PKIX
	enable.auto.commit = true
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.truststore.password = null
	session.timeout.ms = 30000
	metrics.num.samples = 2
	client.id = 
	ssl.endpoint.identification.algorithm = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	check.crcs = true
	request.timeout.ms = 40000
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 1000
	receive.buffer.bytes = 32768
	ssl.cipher.suites = null
	ssl.truststore.type = JKS
	security.protocol = PLAINTEXT
	ssl.truststore.location = null
	ssl.keystore.password = null
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	auto.offset.reset = earliest

[INFO] [2017-06-27 11:00:30][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.9.0.1
[INFO] [2017-06-27 11:00:30][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 23c69d62a0cabf06
[INFO] [2017-06-27 11:03:29][org.apache.kafka.clients.consumer.ConsumerConfig]ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = admin
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [192.168.1.25:32780]
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.keystore.type = JKS
	ssl.trustmanager.algorithm = PKIX
	enable.auto.commit = true
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.truststore.password = null
	session.timeout.ms = 30000
	metrics.num.samples = 2
	client.id = 
	ssl.endpoint.identification.algorithm = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	check.crcs = true
	request.timeout.ms = 40000
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 1000
	receive.buffer.bytes = 32768
	ssl.cipher.suites = null
	ssl.truststore.type = JKS
	security.protocol = PLAINTEXT
	ssl.truststore.location = null
	ssl.keystore.password = null
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	auto.offset.reset = earliest

[INFO] [2017-06-27 11:03:30][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.9.0.1
[INFO] [2017-06-27 11:03:30][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 23c69d62a0cabf06
[INFO] [2017-06-28 17:03:13][org.apache.kafka.clients.consumer.ConsumerConfig]ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = admin
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [192.168.1.25:32780]
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.keystore.type = JKS
	ssl.trustmanager.algorithm = PKIX
	enable.auto.commit = true
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.truststore.password = null
	session.timeout.ms = 30000
	metrics.num.samples = 2
	client.id = 
	ssl.endpoint.identification.algorithm = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	check.crcs = true
	request.timeout.ms = 40000
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 1000
	receive.buffer.bytes = 32768
	ssl.cipher.suites = null
	ssl.truststore.type = JKS
	security.protocol = PLAINTEXT
	ssl.truststore.location = null
	ssl.keystore.password = null
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	auto.offset.reset = earliest

[INFO] [2017-06-28 17:03:14][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.9.0.1
[INFO] [2017-06-28 17:03:14][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 23c69d62a0cabf06
[INFO] [2017-06-29 09:24:51][org.apache.kafka.clients.consumer.ConsumerConfig]ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = admin
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [192.168.1.25:32780]
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.keystore.type = JKS
	ssl.trustmanager.algorithm = PKIX
	enable.auto.commit = true
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.truststore.password = null
	session.timeout.ms = 30000
	metrics.num.samples = 2
	client.id = 
	ssl.endpoint.identification.algorithm = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	check.crcs = true
	request.timeout.ms = 40000
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 1000
	receive.buffer.bytes = 32768
	ssl.cipher.suites = null
	ssl.truststore.type = JKS
	security.protocol = PLAINTEXT
	ssl.truststore.location = null
	ssl.keystore.password = null
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	auto.offset.reset = earliest

[INFO] [2017-06-29 09:24:53][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.9.0.1
[INFO] [2017-06-29 09:24:53][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 23c69d62a0cabf06
